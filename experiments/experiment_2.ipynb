{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a526a5d8",
   "metadata": {},
   "source": [
    "### Experiment2: JD Parsing -  MistralOCR + SLM/LLM (OpenRouter) + LLM_as_a_judge \n",
    "- Maintainer : Shivargha Bandopadhyay\n",
    "- Date : 12/02/2026\n",
    "- Modules : MistralOCR, Langchain  \n",
    "- Pipeline : MistralOCR -> LLM (Ministral 14B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c424d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from mistralai import Mistral \n",
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List,Annotated, Literal,TypedDict,Optional\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eeca4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCRResponse(pages=[OCRPageObject(index=0, markdown='# Lead Data Scientist\\n\\nBengaluru\\n\\nWork Experience: 8+ years\\n\\n## Mandate Skills:\\n\\n- Experience in Programming (Python, R, SQL, NoSQL, Spark) with ML tools &amp; Cloud Technology (AWS, Azure, GCP)\\n- Experience in Python libraries such as numpy, pandas, scikit-learn, tensor-flow, scapy, scrapy, BERT etc.\\n- Good understanding in statistics, and ability to design statistical hypothesis testing to aid formal decision making.\\n- Develops predictive models using Machine Learning algorithms (SVM, Random Forest, Neural Network, Decision Tree, Logistic Regression, K-mean Clustering, linear regression, PCA etc.)\\n- Engaging with clients, understanding complex problem statements, and offering solutions in the domains of Retail, Pharma, Banking, Insurance, etc.\\n- Contribute to internal product development initiatives related to data science.\\n- Develop data science roadmap, and guide data scientist to meet their deliverables.\\n- Handling end-to-end client AI &amp; analytics programs. Your role will be a combination of hands-on contribution, technical team management, and client interaction.\\n- Proven ability to discover solutions hidden in large datasets and to drive business results with their data-based insights\\n- Drive excellent project management required to deliver complex projects, including effort/time estimation.\\n- Be proactive, with full ownership of the engagement. Build scalable client engagement level processes for faster turnaround &amp; higher accuracy\\n- Define Technology/ Strategy and Roadmap for client accounts, and guides implementation of that strategy within projects\\n- Run regular project reviews and audits to ensure that projects are being executed within the guardrails agreed by all stakeholders\\n- Manage the team-members, to ensure that the project plan is being adhered to over the course of the project', images=[], dimensions=OCRPageDimensions(dpi=200, height=2339, width=1654), tables=[], hyperlinks=[], header=None, footer=None), OCRPageObject(index=1, markdown='- Manage the client stakeholders, and their expectations, with a regular cadence of weekly meetings and status updates.\\n- Build a trusted advisor relationship with the IT management at clients and internal accounts leadership.\\n- Build business case for technological investments to be made for future needs and to remain competitive\\n- Ensure that billing and utilization of team members is maximized throughout the year\\n\\n## Desired Skills:\\n- Experience designing data science solutions to business problems\\n- Deep understanding of ML algorithms for common use cases in both structured and unstructured data ecosystems.\\n- Comfortable with large scale data processing and distributed computing\\n- Allocates workload among team members and by taking into consideration employee availability, skill set, and current workload when making assignments.\\n- Providing required inputs to sales, and pre-sales activities\\n- Excellent written and verbal communication skills', images=[], dimensions=OCRPageDimensions(dpi=200, height=2339, width=1654), tables=[], hyperlinks=[], header=None, footer=None)], model='mistral-ocr-latest', usage_info=OCRUsageInfo(pages_processed=2, doc_size_bytes=127006), document_annotation=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MISTRAL OCR ###\n",
    "'''\n",
    "Local Files Need to be uploaded to Mistral OCR - storage\n",
    "Use Mistral OCR API to extract text from the uploaded file URL Link\n",
    "'''\n",
    "client = Mistral(api_key=MISTRAL_API_KEY)\n",
    "def upload_file(file_path:str) -> str:\n",
    "\n",
    "    filename = file_path.split(\"\\\\\")[-1]\n",
    "\n",
    "    ## Upload File to Mistral OCR Storage ##\n",
    "    uploaded_file = client.files.upload(\n",
    "        file = {\n",
    "            \"file_name\": filename,\n",
    "            \"content\": open(file_path, \"rb\")\n",
    "        },\n",
    "        purpose = 'ocr'\n",
    "    )\n",
    "\n",
    "    signed_url = client.files.get_signed_url(file_id=uploaded_file.id)\n",
    "    return signed_url.url\n",
    "\n",
    "def get_ocr_response(file_url:str):\n",
    "\n",
    "    ## Get OCR Response ##\n",
    "    ocr_response = client.ocr.process(\n",
    "        model = 'mistral-ocr-latest',\n",
    "        document = {\n",
    "            \"type\": \"document_url\",\n",
    "            \"document_url\":file_url\n",
    "        },\n",
    "        include_image_base64 = True    \n",
    "    )\n",
    "\n",
    "    return ocr_response\n",
    "\n",
    "url = upload_file(\"D:\\\\Tvarah\\\\resume_extraction\\\\data\\\\Job Description\\\\Data Science\\\\Lead Data Scientist.pdf\")\n",
    "ocr_response = get_ocr_response(url)\n",
    "ocr_response \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83f9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_combined = ' '.join(i.markdown for i in ocr_response.pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0286fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Templates ###\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "### ROLE\n",
    "You are a Technical Recruiter AI. Your job is to extract structured matching criteria from a messy Job Description.\n",
    "\n",
    "### INSTRUCTIONS\n",
    "1. **Ignore the Fluff:** Do not extract text from the \"About Us\" or \"Culture\" sections unless it specifies a hard requirement (e.g., \"Must work EST timezone\").\n",
    "2. **Distinguish Requirements:**\n",
    "   - If a skill says \"Required\", \"Must have\", or \"Proficient in\", put it in `mandatory_skills`.\n",
    "   - If a skill says \"Bonus\", \"Plus\", \"Good to have\", or \"Familiarity with\", put it in `optional_skills`.\n",
    "3. **Formatting:**\n",
    "   - Skills should be single keywords (e.g., \"Python\", \"AWS\", \"React\"). Do not write sentences.\n",
    "\"\"\"   \n",
    ")\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Here is the JobDescription Markdown:\n",
    "    <job_description>\n",
    "    {job_description_markdown}\n",
    "    </job_description>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, human_prompt]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e705e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skillsInfo(BaseModel):\n",
    "    programming_languages: list[str] = Field(default=[],description=\"Programming languages as required,\\\n",
    "        Ex: Python,C,C++ etc if not present then return None\")\n",
    "    frameworks_and_libraries: list[str] = Field(default=[],description=\"Frameworks and libraries as required, \\\n",
    "        Ex: React,Angular,Django,Flask,Pandas,Pytorch etc if not present then return None\")\n",
    "    tools: list[str] = Field(default=[],description=\"Tools as required,\\\n",
    "        Ex: Git,Docker,Kubernetes,Jenkins,Jira,etc. if not present then return None\")\n",
    "    databases: list[str] = Field(default=[],description=\"Databases as required, \\\n",
    "        Ex: MySQL,PostgreSQL,MongoDB,Oracle,etc. if not present then return None\")\n",
    "    cloud_and_infra: list[str] = Field(default=[],description=\"Cloud and infra as required,\\\n",
    "        Ex: AWS,Azure,GCP,etc. if not present then return None\")\n",
    "\n",
    "class JobDescription(BaseModel):\n",
    "    # --- METADATA (For the UI) ---\n",
    "    role_title: str = Field(..., description=\"The standard job title, e.g., 'Senior Backend Engineer'\")\n",
    "    company_name: Optional[str] = Field(default=None, description=\"Name of the company\")\n",
    "    salary_range: Optional[str] = Field(None, description=\"e.g. '$120k - $160k'\")\n",
    "\n",
    "    # Hard Skills (The \"Must Haves\")\n",
    "    mandatory_skills: skillsInfo = Field(..., description=\"Technical skills explicitly marked as required\")\n",
    "    \n",
    "    # Soft Skills / Bonus (The \"Nice to Haves\")\n",
    "    optional_skills: List[str] = Field([], description=\"Skills listed as 'preferred', 'bonus', or 'plus'\")\n",
    "    \n",
    "    # Experience Constraint (Normalize this!)\n",
    "    min_years_experience: Optional[int] = Field(None, description=\"Integer value of required years. e.g. '5+ years' -> 5\")\n",
    "    \n",
    "    # Education Constraint\n",
    "    degree_required: Optional[str] = Field(None, description=\"e.g. 'Bachelor in CS', 'PhD'\")\n",
    "\n",
    "    # --- THE SUMMARY (For the Human) ---\n",
    "    summary_responsibilities: List[str] = Field(..., description=\"Top 3-5 core responsibilities summarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d5f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"role_title\": \"Lead Data Scientist\",\n",
      "    \"company_name\": null,\n",
      "    \"salary_range\": null,\n",
      "    \"mandatory_skills\": {\n",
      "        \"programming_languages\": [\n",
      "            \"Python\",\n",
      "            \"R\",\n",
      "            \"SQL\",\n",
      "            \"NoSQL\"\n",
      "        ],\n",
      "        \"frameworks_and_libraries\": [\n",
      "            \"numpy\",\n",
      "            \"pandas\",\n",
      "            \"scikit-learn\",\n",
      "            \"tensorflow\",\n",
      "            \"scapy\",\n",
      "            \"scrapy\",\n",
      "            \"BERT\",\n",
      "            \"Spark\"\n",
      "        ],\n",
      "        \"tools\": [],\n",
      "        \"databases\": [],\n",
      "        \"cloud_and_infra\": [\n",
      "            \"AWS\",\n",
      "            \"Azure\",\n",
      "            \"GCP\"\n",
      "        ]\n",
      "    },\n",
      "    \"optional_skills\": [\n",
      "        \"statistics\",\n",
      "        \"statistical hypothesis testing\",\n",
      "        \"SVM\",\n",
      "        \"Random Forest\",\n",
      "        \"Neural Network\",\n",
      "        \"Decision Tree\",\n",
      "        \"Logistic Regression\",\n",
      "        \"K-means Clustering\",\n",
      "        \"linear regression\",\n",
      "        \"PCA\",\n",
      "        \"large scale data processing\",\n",
      "        \"distributed computing\",\n",
      "        \"project management\",\n",
      "        \"effort/time estimation\",\n",
      "        \"client engagement processes\",\n",
      "        \"project reviews and audits\",\n",
      "        \"stakeholder management\",\n",
      "        \"technical strategy and roadmap definition\",\n",
      "        \"business case development for technological investments\",\n",
      "        \"billing and utilization management\",\n",
      "        \"sales and pre-sales support\",\n",
      "        \"written and verbal communication skills\"\n",
      "    ],\n",
      "    \"min_years_experience\": 8,\n",
      "    \"degree_required\": null,\n",
      "    \"summary_responsibilities\": [\n",
      "        \"Develop predictive models using ML algorithms and guide data science teams to meet deliverables\",\n",
      "        \"Handle end-to-end client AI & analytics programs, including hands-on contributions, technical team management, and client interaction\",\n",
      "        \"Drive business results through data-based insights and manage client engagements with regular reviews and stakeholder updates\",\n",
      "        \"Define technology strategy and roadmap for client accounts and ensure project execution aligns with stakeholder agreements\",\n",
      "        \"Build trusted advisor relationships with client IT management and internal leadership\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "llm_model = ChatOpenAI(\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    api_key = OPENROUTER_API_KEY,\n",
    "    model = \"mistralai/ministral-14b-2512\",\n",
    ")\n",
    "chain = prompt_template | llm_model.with_structured_output(JobDescription)\n",
    "response = chain.invoke({\"job_description_markdown\": markdown_combined})\n",
    "print(response.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c1290d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM as judge ##\n",
    "llm_model_judge = ChatOpenAI(\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    api_key = OPENROUTER_API_KEY,\n",
    "    model = \"microsoft/phi-4\",\n",
    ")\n",
    "\n",
    "class judgeJson(BaseModel):\n",
    "    grade: str = Field(...,description=\"Pass or Fail\")\n",
    "    grade_summary: str = Field(...,description=\"Summary of what things are right or what is wrong with the extraction\")\n",
    "\n",
    "judge_system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    '''\n",
    "    ### ROLE\n",
    "    You are a strict QA Auditor for a Resume & JD Parsing pipeline. \n",
    "    Your job is to compare the SOURCE_TEXT (Markdown) with the EXTRACTED_JSON.\n",
    "\n",
    "    ### TASK\n",
    "    Verify the JSON against the text for three specific errors:\n",
    "    1. **Hallucinations:** Did the JSON invent a skill, job, or degree not present in the text?\n",
    "    2. **Date Errors:** Are the start/end dates in the JSON supported by the text?\n",
    "    3. **Missing Critical Data:** Did the JSON return 'null' for a name or email that is clearly visible in the text?\n",
    "\n",
    "    ### OUTPUT FORMAT\n",
    "    Return valid JSON with two fields:\n",
    "    - \"verdict\": \"PASS\" or \"FAIL\"\n",
    "    - \"reason\": \"Short explanation of the error (if FAIL), otherwise 'looks good'. in about a single line (100 words)\"\n",
    "\n",
    "    ### CONSTRAINTS\n",
    "    - Ignore minor formatting differences (e.g., \"Software Eng.\" vs \"Software Engineer\" is acceptable).\n",
    "    - Be strict about Dates and Numbers.\n",
    "     \n",
    "    '''\n",
    ")\n",
    "\n",
    "human_prompt_judge = HumanMessagePromptTemplate.from_template(\n",
    "    '''\n",
    "    Here is the markdown extraction:\n",
    "    <markdown>\n",
    "    {markdown}\n",
    "    </markdown>\n",
    "\n",
    "    Here is the Json extraction:\n",
    "    <jsondata>\n",
    "    {jsondata}\n",
    "    </jsondata>\n",
    "    '''\n",
    ")\n",
    "\n",
    "prompt_template_judge = ChatPromptTemplate.from_messages(\n",
    "    [judge_system_prompt,human_prompt_judge]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "566bc742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"grade\": \"PASS\",\n",
      "    \"grade_summary\": \"The JSON reflects the information present in the Markdown source text accurately without any hallucination of skills or degrees. It correctly extracts the specified work experience and proficiency in various programming language and machine learning libraries. The extraction omits company names but includes the location 'Bengaluru,' which while not ideal, does not contain any critical errors as company names are not explicitly stated in the source text. The desired role title 'Lead Data Scientist' aligns with the role title extracted from the source text. Dates and numbers are consistent, with no 'null' values present for any critical data such as names or emails, which are not mentioned in the source text but do not contribute to errors as no 'null' critical information is missing. Overall, the extracted JSON accurately reflects key contents, adjusting slightly due to formatting expectations from the source text, consistent with what a strict QA auditor would expect, thus confirming the 'PASS' verdict.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template_judge | llm_model_judge.with_structured_output(judgeJson)\n",
    "response = chain.invoke({\"markdown\": markdown_combined,\"jsondata\":response.model_dump_json(indent=4)})\n",
    "print(response.model_dump_json(indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
